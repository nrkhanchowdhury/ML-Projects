{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, valid, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32198b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Data ===\n",
    "import pandas as pd\n",
    "X = pd.read_csv(\"X_transaction_data.csv\")\n",
    "y = pd.read_csv(\"y_transaction_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d76b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (80%), validation (10%), test (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDA ===\n",
    "print(\"Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_valid: {X_valid.shape}, y_valid: {y_valid.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(X_train.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = X_train.select_dtypes(include='number').corr()\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.use_inf_as_na', True)\n",
    "# Convert the categorical features to numerical for pairplot (for visualization purposes)\n",
    "X_eda = X_train.copy()\n",
    "X_eda['type'] = X_eda['type'].astype('category').cat.codes\n",
    "X_eda['sender_location'] = X_eda['sender_location'].astype('category').cat.codes\n",
    "X_eda['receiver_location'] = X_eda['receiver_location'].astype('category').cat.codes\n",
    "X_eda['time_of_day'] = X_eda['time_of_day'].astype('category').cat.codes\n",
    "X_eda['device_type'] = X_eda['device_type'].astype('category').cat.codes\n",
    "X_eda['category'] = X_eda['category'].astype('category').cat.codes\n",
    "\n",
    "# Combine features with the target for pairplot\n",
    "X_eda['fraudulent'] = y\n",
    "\n",
    "# Pairplot for numerical relationships\n",
    "sns.pairplot(X_eda, hue='fraudulent', diag_kind='kde', plot_kws={'alpha': 0.5})\n",
    "plt.title(\"Pairplot for Transaction Data (Colored by Fraudulent Transactions)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train + valid\n",
    "X_trainval = np.vstack([X_train.select_dtypes(include='number'), X_valid.select_dtypes(include='number')])\n",
    "y_trainval = np.vstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define TNR Scorer ===\n",
    "def tnr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp + 1e-10)\n",
    "\n",
    "# === Hyperopt Objective Function ===\n",
    "def objective_rf(params):\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, X_trainval, y_trainval, cv=cv, method='predict')\n",
    "    score = tnr_score(y_trainval, y_pred)\n",
    "    return {'loss': 1 - score, 'status': STATUS_OK, 'tnr': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperopt Search Space ===\n",
    "space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 20, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1690c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run Hyperopt ===\n",
    "trials_rf = Trials()\n",
    "best_rf = fmin(\n",
    "    fn=objective_rf,\n",
    "    space=space_rf,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials_rf,\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "print(\"\\nBest RF Hyperparameters:\")\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parallel Coordinates Plot ===\n",
    "results = []\n",
    "for trial in trials_rf.trials:\n",
    "    vals = trial['misc']['vals']\n",
    "    results.append({\n",
    "        'n_estimators': int(vals['n_estimators'][0]),\n",
    "        'max_depth': int(vals['max_depth'][0]),\n",
    "        'min_samples_split': int(vals['min_samples_split'][0]),\n",
    "        'min_samples_leaf': int(vals['min_samples_leaf'][0]),\n",
    "        'TNR': 1 - trial['result']['loss']\n",
    "    })\n",
    "df_rf = pd.DataFrame(results)\n",
    "\n",
    "#cool hack\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "\n",
    "fig = px.parallel_coordinates(\n",
    "    df_rf,\n",
    "    color=\"TNR\",\n",
    "    labels={\n",
    "        \"n_estimators\": \"n_estimators\",\n",
    "        \"max_depth\": \"max_depth\",\n",
    "        \"min_samples_split\": \"min_samples_split\",\n",
    "        \"min_samples_leaf\": \"min_samples_leaf\",\n",
    "        \"TNR\": \"TNR\"\n",
    "    },\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    ")\n",
    "fig.update_layout(title=\"Random Forest Hyperparameter Tuning (TNR Optimized)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc27ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Evaluation ===\n",
    "best_rf_clean = {\n",
    "    'n_estimators': int(best_rf['n_estimators']),\n",
    "    'max_depth': int(best_rf['max_depth']),\n",
    "    'min_samples_split': int(best_rf['min_samples_split']),\n",
    "    'min_samples_leaf': int(best_rf['min_samples_leaf']),\n",
    "}\n",
    "\n",
    "final_rf = RandomForestClassifier(\n",
    "    **best_rf_clean,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_rf.fit(X_trainval, y_trainval)\n",
    "y_pred_rf = final_rf.predict(X_test.select_dtypes(include='number')) # only num values\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tnr = tn / (tn + fp + 1e-10)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negative Rate (TNR): {tnr:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac93883",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# === Feature Importance ===\n",
    "feature_names = X_train.select_dtypes(include='number').columns\n",
    "importances = final_rf.feature_importances_\n",
    "feat_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "feat_df = feat_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_df.head(15), x=\"Importance\", y=\"Feature\")\n",
    "plt.title(\"Top 15 Feature Importances (RF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SHAP Plot ===\n",
    "import shap\n",
    "explainer = shap.Explainer(final_rf, X_trainval, feature_names=feature_names)\n",
    "shap_values = explainer(X_test.select_dtypes(include='number'))\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values, features=X_test.select_dtypes(include='number'), feature_names=feature_names, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, features=X_test.select_dtypes(include='number'), feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91158bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Predict Probabilities ===\n",
    "y_proba_rf = final_rf.predict_proba(X_test.select_dtypes(include='number'))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ROC Curve and AUC ===\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba_rf)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Precision-Recall Curve and PR AUC ===\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_proba_rf)\n",
    "pr_auc = average_precision_score(y_test, y_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.3f}\", color=\"green\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5616ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TNR vs. Threshold Plot ===\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "tnr_list = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    preds = (y_proba_rf >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    tnr = tn / (tn + fp + 1e-10)\n",
    "    tnr_list.append(tnr)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(thresholds, tnr_list, color='purple')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"True Negative Rate (TNR)\")\n",
    "plt.title(\"TNR vs. Classification Threshold\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TNR vs. Threshold Plot ===\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "fnr_list = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    preds = (y_proba_rf >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    fnr = tn / (tn + fp + 1e-10)\n",
    "    fnr_list.append(fnr)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(thresholds, fnr_list, color='red')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"False Negative Rate (FNR)\")\n",
    "plt.title(\"FNR vs. Classification Threshold\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Load Data ===\n",
    "#X_train = pd.read_csv(\"X_train_transaction_data.csv\")\n",
    "#y_train = pd.read_csv(\"y_train_transaction_labels.csv\")[\"fraudulent\"]\n",
    "#X_valid = pd.read_csv(\"X_valid_transaction_data.csv\")\n",
    "#y_valid = pd.read_csv(\"y_valid_transaction_labels.csv\")[\"fraudulent\"]\n",
    "#X_test = pd.read_csv(\"X_test_transaction_data.csv\")\n",
    "#y_test = pd.read_csv(\"y_test_transaction_labels.csv\")[\"fraudulent\"]\n",
    "\n",
    "# === EDA ===\n",
    "print(\"Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "#sns.countplot(x=y_train)\n",
    "#plt.title(\"Class Distribution in y_train\")\n",
    "#plt.show()\n",
    "\n",
    "X_corr = X_train.copy()\n",
    "for col in X_corr.select_dtypes(include='object'):\n",
    "    X_corr[col] = X_corr[col].astype(\"category\").cat.codes\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_corr.corr(), cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "X_pair = X_corr.copy()\n",
    "X_pair[\"fraudulent\"] = y_train\n",
    "sns.pairplot(X_pair.sample(500), hue=\"fraudulent\", diag_kind=\"kde\")\n",
    "plt.suptitle(\"Pairplot (500 samples)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# === Preprocessing ===\n",
    "cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "for col in cat_cols:\n",
    "    for df in [X_train, X_valid, X_test]:\n",
    "        df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_valid_imp = imputer.transform(X_valid)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_valid_scaled = scaler.transform(X_valid_imp)\n",
    "X_test_scaled = scaler.transform(X_test_imp)\n",
    "\n",
    "X_trainval = np.vstack([X_train_scaled, X_valid_scaled])\n",
    "y_trainval = np.vstack([y_train, y_valid])\n",
    "\n",
    "# === Define TNR Scorer ===\n",
    "def tnr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp + 1e-10)\n",
    "\n",
    "# === Hyperopt for Random Forest ===\n",
    "def objective_rf(params):\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, X_trainval, y_trainval, cv=cv)\n",
    "    return {'loss': 1 - tnr_score(y_trainval, y_pred), 'status': STATUS_OK}\n",
    "\n",
    "space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 20, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1)\n",
    "}\n",
    "\n",
    "trials_rf = Trials()\n",
    "best_rf = fmin(fn=objective_rf, space=space_rf, algo=tpe.suggest, max_evals=50, trials=trials_rf, rstate=np.random.default_rng(42))\n",
    "\n",
    "# === Train Final RF ===\n",
    "best_params_rf = {\n",
    "    'n_estimators': int(best_rf['n_estimators']),\n",
    "    'max_depth': int(best_rf['max_depth']),\n",
    "    'min_samples_split': int(best_rf['min_samples_split']),\n",
    "    'min_samples_leaf': int(best_rf['min_samples_leaf'])\n",
    "}\n",
    "\n",
    "final_rf = RandomForestClassifier(**best_params_rf, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "final_rf.fit(X_trainval, y_trainval)\n",
    "y_pred_rf = final_rf.predict(X_test_scaled)\n",
    "y_proba_rf = final_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# === Evaluation ===\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"TNR: {tn / (tn + fp + 1e-10):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# === Feature Importance ===\n",
    "feat_df = pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": final_rf.feature_importances_})\n",
    "feat_df = feat_df.sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_df.head(15), x=\"Importance\", y=\"Feature\")\n",
    "plt.title(\"Top 15 Feature Importances (RF)\")\n",
    "plt.show()\n",
    "\n",
    "# === SHAP ===\n",
    "explainer = shap.Explainer(final_rf, X_trainval)\n",
    "shap_values = explainer(X_test_scaled)\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns)\n",
    "\n",
    "# === Threshold Sensitivity ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_rf)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_rf)\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "pr_auc = average_precision_score(y_test, y_proba_rf)\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.3f}\", color='green')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "tnr_list = []\n",
    "fnr_list = []\n",
    "for thresh in thresholds:\n",
    "    preds = (y_proba_rf >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    tnr_list.append(tn / (tn + fp + 1e-10))\n",
    "    fnr_list.append(fn / (fn + tp + 1e-10))\n",
    "\n",
    "plt.plot(thresholds, tnr_list, color='purple')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"TNR\")\n",
    "plt.title(\"TNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(thresholds, fnr_list, color='red')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"FNR\")\n",
    "plt.title(\"FNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33df9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5627f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66403170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a625b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Load Data ===\n",
    "X_train = pd.read_csv(\"X_train_transaction_data.csv\")\n",
    "y_train = pd.read_csv(\"y_train_transaction_labels.csv\")[\"fraudulent\"]\n",
    "X_valid = pd.read_csv(\"X_valid_transaction_data.csv\")\n",
    "y_valid = pd.read_csv(\"y_valid_transaction_labels.csv\")[\"fraudulent\"]\n",
    "X_test = pd.read_csv(\"X_test_transaction_data.csv\")\n",
    "y_test = pd.read_csv(\"y_test_transaction_labels.csv\")[\"fraudulent\"]\n",
    "\n",
    "# === EDA ===\n",
    "print(\"Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Class Distribution in y_train\")\n",
    "plt.show()\n",
    "\n",
    "X_corr = X_train.copy()\n",
    "for col in X_corr.select_dtypes(include='object'):\n",
    "    X_corr[col] = X_corr[col].astype(\"category\").cat.codes\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_corr.corr(), cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "X_pair = X_corr.copy()\n",
    "X_pair[\"fraudulent\"] = y_train\n",
    "sns.pairplot(X_pair.sample(500), hue=\"fraudulent\", diag_kind=\"kde\")\n",
    "plt.suptitle(\"Pairplot (500 samples)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# === Preprocessing ===\n",
    "cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "for col in cat_cols:\n",
    "    for df in [X_train, X_valid, X_test]:\n",
    "        df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_valid_imp = imputer.transform(X_valid)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_valid_scaled = scaler.transform(X_valid_imp)\n",
    "X_test_scaled = scaler.transform(X_test_imp)\n",
    "\n",
    "X_trainval = np.vstack([X_train_scaled, X_valid_scaled])\n",
    "y_trainval = np.hstack([y_train, y_valid])\n",
    "\n",
    "# === Define TNR Scorer ===\n",
    "def tnr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp + 1e-10)\n",
    "\n",
    "# === Hyperopt for LightGBM ===\n",
    "def objective_lgb(params):\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=params['scale_pos_weight'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, X_trainval, y_trainval, cv=cv)\n",
    "    return {'loss': 1 - tnr_score(y_trainval, y_pred), 'status': STATUS_OK}\n",
    "\n",
    "space_lgb = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10)\n",
    "}\n",
    "\n",
    "trials_lgb = Trials()\n",
    "best_lgb = fmin(fn=objective_lgb, space=space_lgb, algo=tpe.suggest, max_evals=50, trials=trials_lgb, rstate=np.random.default_rng(42))\n",
    "\n",
    "# === Train Final LightGBM ===\n",
    "best_params_lgb = {\n",
    "    'n_estimators': int(best_lgb['n_estimators']),\n",
    "    'max_depth': int(best_lgb['max_depth']),\n",
    "    'learning_rate': best_lgb['learning_rate'],\n",
    "    'subsample': best_lgb['subsample'],\n",
    "    'colsample_bytree': best_lgb['colsample_bytree'],\n",
    "    'scale_pos_weight': best_lgb['scale_pos_weight']\n",
    "}\n",
    "\n",
    "final_lgb = lgb.LGBMClassifier(**best_params_lgb, random_state=42, n_jobs=-1)\n",
    "final_lgb.fit(X_trainval, y_trainval)\n",
    "y_pred_lgb = final_lgb.predict(X_test_scaled)\n",
    "y_proba_lgb = final_lgb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# === Evaluation ===\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"TNR: {tn / (tn + fp + 1e-10):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# === Feature Importance ===\n",
    "feat_df = pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": final_lgb.feature_importances_})\n",
    "feat_df = feat_df.sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_df.head(15), x=\"Importance\", y=\"Feature\")\n",
    "plt.title(\"Top 15 Feature Importances (LightGBM)\")\n",
    "plt.show()\n",
    "\n",
    "# === SHAP ===\n",
    "explainer = shap.Explainer(final_lgb, X_trainval)\n",
    "shap_values = explainer(X_test_scaled)\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns)\n",
    "\n",
    "# === Threshold Sensitivity ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_lgb)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_lgb)\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_lgb)\n",
    "pr_auc = average_precision_score(y_test, y_proba_lgb)\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.3f}\", color='green')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "tnr_list = []\n",
    "fnr_list = []\n",
    "for thresh in thresholds:\n",
    "    preds = (y_proba_lgb >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    tnr_list.append(tn / (tn + fp + 1e-10))\n",
    "    fnr_list.append(fn / (fn + tp + 1e-10))\n",
    "\n",
    "plt.plot(thresholds, tnr_list, color='purple')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"TNR\")\n",
    "plt.title(\"TNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(thresholds, fnr_list, color='red')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"FNR\")\n",
    "plt.title(\"FNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Load Data ===\n",
    "X_train = pd.read_csv(\"X_train_transaction_data.csv\")\n",
    "y_train = pd.read_csv(\"y_train_transaction_labels.csv\")[\"fraudulent\"]\n",
    "X_valid = pd.read_csv(\"X_valid_transaction_data.csv\")\n",
    "y_valid = pd.read_csv(\"y_valid_transaction_labels.csv\")[\"fraudulent\"]\n",
    "X_test = pd.read_csv(\"X_test_transaction_data.csv\")\n",
    "y_test = pd.read_csv(\"y_test_transaction_labels.csv\")[\"fraudulent\"]\n",
    "\n",
    "# === EDA ===\n",
    "print(\"Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Class Distribution in y_train\")\n",
    "plt.show()\n",
    "\n",
    "X_corr = X_train.copy()\n",
    "for col in X_corr.select_dtypes(include='object'):\n",
    "    X_corr[col] = X_corr[col].astype(\"category\").cat.codes\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_corr.corr(), cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "X_pair = X_corr.copy()\n",
    "X_pair[\"fraudulent\"] = y_train\n",
    "sns.pairplot(X_pair.sample(500), hue=\"fraudulent\", diag_kind=\"kde\")\n",
    "plt.suptitle(\"Pairplot (500 samples)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# === Preprocessing ===\n",
    "cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "for col in cat_cols:\n",
    "    for df in [X_train, X_valid, X_test]:\n",
    "        df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_valid_imp = imputer.transform(X_valid)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_valid_scaled = scaler.transform(X_valid_imp)\n",
    "X_test_scaled = scaler.transform(X_test_imp)\n",
    "\n",
    "X_trainval = np.vstack([X_train_scaled, X_valid_scaled])\n",
    "y_trainval = np.hstack([y_train, y_valid])\n",
    "\n",
    "# === Define TNR Scorer ===\n",
    "def tnr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp + 1e-10)\n",
    "\n",
    "# === Hyperopt for XGBoost ===\n",
    "def objective_xgb(params):\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=params['scale_pos_weight'],\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, X_trainval, y_trainval, cv=cv)\n",
    "    return {'loss': 1 - tnr_score(y_trainval, y_pred), 'status': STATUS_OK}\n",
    "\n",
    "space_xgb = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10)\n",
    "}\n",
    "\n",
    "trials_xgb = Trials()\n",
    "best_xgb = fmin(fn=objective_xgb, space=space_xgb, algo=tpe.suggest, max_evals=50, trials=trials_xgb, rstate=np.random.default_rng(42))\n",
    "\n",
    "# === Train Final XGBoost ===\n",
    "best_params_xgb = {\n",
    "    'n_estimators': int(best_xgb['n_estimators']),\n",
    "    'max_depth': int(best_xgb['max_depth']),\n",
    "    'learning_rate': best_xgb['learning_rate'],\n",
    "    'subsample': best_xgb['subsample'],\n",
    "    'colsample_bytree': best_xgb['colsample_bytree'],\n",
    "    'scale_pos_weight': best_xgb['scale_pos_weight']\n",
    "}\n",
    "\n",
    "final_xgb = XGBClassifier(**best_params_xgb, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "final_xgb.fit(X_trainval, y_trainval)\n",
    "y_pred_xgb = final_xgb.predict(X_test_scaled)\n",
    "y_proba_xgb = final_xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# === Evaluation ===\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"TNR: {tn / (tn + fp + 1e-10):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# === Feature Importance ===\n",
    "feat_df = pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": final_xgb.feature_importances_})\n",
    "feat_df = feat_df.sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_df.head(15), x=\"Importance\", y=\"Feature\")\n",
    "plt.title(\"Top 15 Feature Importances (XGBoost)\")\n",
    "plt.show()\n",
    "\n",
    "# === SHAP ===\n",
    "explainer = shap.Explainer(final_xgb)\n",
    "shap_values = explainer(X_test_scaled)\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, features=X_test_scaled, feature_names=X_train.columns)\n",
    "\n",
    "# === Threshold Sensitivity ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_xgb)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_xgb)\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_xgb)\n",
    "pr_auc = average_precision_score(y_test, y_proba_xgb)\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.3f}\", color='green')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "tnr_list = []\n",
    "fnr_list = []\n",
    "for thresh in thresholds:\n",
    "    preds = (y_proba_xgb >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    tnr_list.append(tn / (tn + fp + 1e-10))\n",
    "    fnr_list.append(fn / (fn + tp + 1e-10))\n",
    "\n",
    "plt.plot(thresholds, tnr_list, color='purple')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"TNR\")\n",
    "plt.title(\"TNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(thresholds, fnr_list, color='red')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"FNR\")\n",
    "plt.title(\"FNR vs. Threshold\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example metrics per model — replace with your actual calculated values\n",
    "metrics = {\n",
    "    'RF':    {'Precision': 0.88, 'Recall': 0.70, 'Accuracy': 0.91, 'TNR': 0.97, 'FNR': 0.30, 'TPR': 0.70, 'FPR': 0.03, 'ROC AUC': 0.93, 'PR AUC': 0.78},\n",
    "    'XGB':   {'Precision': 0.86, 'Recall': 0.72, 'Accuracy': 0.90, 'TNR': 0.96, 'FNR': 0.28, 'TPR': 0.72, 'FPR': 0.04, 'ROC AUC': 0.92, 'PR AUC': 0.80},\n",
    "    'LGBM':  {'Precision': 0.89, 'Recall': 0.75, 'Accuracy': 0.92, 'TNR': 0.98, 'FNR': 0.25, 'TPR': 0.75, 'FPR': 0.02, 'ROC AUC': 0.94, 'PR AUC': 0.83},\n",
    "}\n",
    "\n",
    "labels = list(metrics['RF'].keys())\n",
    "models = list(metrics.keys())\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]  # repeat first angle for closing the plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n",
    "for model in models:\n",
    "    values = [metrics[model][m] for m in labels]\n",
    "    values += values[:1]  # close the circle\n",
    "    ax.plot(angles, values, label=model)\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_title(\"Model Comparison Radar Chart\", size=14)\n",
    "ax.grid(True)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e281d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, confusion_matrix\n",
    "\n",
    "# === Placeholder Predictions (load your actual predictions here) ===\n",
    "# Replace with real probability outputs from your models on the same test set\n",
    "#y_test = pd.read_csv(\"y_test_transaction_labels.csv\")[\"fraudulent\"]\n",
    "\n",
    "# Example placeholders (replace with your predictions)\n",
    "#y_proba_rf = pd.read_csv(\"rf_probs.csv\")[\"prob\"]\n",
    "#y_proba_xgb = pd.read_csv(\"xgb_probs.csv\")[\"prob\"]\n",
    "#y_proba_lgb = pd.read_csv(\"lgb_probs.csv\")[\"prob\"]\n",
    "\n",
    "# === Compute Metrics ===\n",
    "def compute_metrics(y_true, y_proba):\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    preds = (y_proba > 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "    tnr = tn / (tn + fp + 1e-10)\n",
    "    return auc, pr_auc, tnr\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": y_proba_rf,\n",
    "    \"XGBoost\": y_proba_xgb,\n",
    "    \"LightGBM\": y_proba_lgb\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, y_proba in models.items():\n",
    "    auc, pr_auc, tnr = compute_metrics(y_test, y_proba)\n",
    "    results[name] = {\"ROC AUC\": auc, \"PR AUC\": pr_auc, \"TNR\": tnr}\n",
    "\n",
    "# === Display Results ===\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(results_df.sort_values(\"TNR\", ascending=False))\n",
    "\n",
    "# === Plot Comparison ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, y_proba in models.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"{name}\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, y_proba in models.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    plt.plot(recall, precision, label=f\"{name}\")\n",
    "plt.title(\"Precision-Recall Curves\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# === Optional: Ensemble ===\n",
    "ensemble_proba = (y_proba_rf + y_proba_xgb + y_proba_lgb) / 3\n",
    "ensemble_metrics = compute_metrics(y_test, ensemble_proba)\n",
    "print(\"\\nEnsemble Performance:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "# --- Function to calculate metrics ---\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    tnr = tn / (tn + fp + 1e-10)\n",
    "    fnr = fn / (fn + tp + 1e-10)\n",
    "    tpr = recall  # True Positive Rate is equivalent to Recall\n",
    "    fpr = fp / (fp + tn + 1e-10)\n",
    "    \n",
    "    # ROC AUC and PR AUC scores\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    \n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'TNR': tnr,\n",
    "        'FNR': fnr,\n",
    "        'TPR': tpr,\n",
    "        'FPR': fpr,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'PR AUC': pr_auc\n",
    "    }\n",
    "\n",
    "# --- Calculate metrics for each model ---\n",
    "# Replace `y_pred_*` and `y_proba_*` with predictions and probabilities from your models\n",
    "# For example, for Random Forest:\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Repeat for other models (XGBoost, LGBM):\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
    "y_proba_lgbm = lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Store metrics in a dictionary ---\n",
    "metrics = {\n",
    "    'RF': calculate_metrics(y_test, y_pred_rf, y_proba_rf),\n",
    "    'XGB': calculate_metrics(y_test, y_pred_xgb, y_proba_xgb),\n",
    "    'LGBM': calculate_metrics(y_test, y_pred_lgbm, y_proba_lgbm),\n",
    "}\n",
    "\n",
    "# --- Radar Plot ---\n",
    "labels = list(metrics['RF'].keys())  # Using RF as the reference for label names\n",
    "models = list(metrics.keys())\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]  # repeat first angle for closing the plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n",
    "for model in models:\n",
    "    values = [metrics[model][m] for m in labels]\n",
    "    values += values[:1]  # close the circle\n",
    "    ax.plot(angles, values, label=model)\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_title(\"Model Comparison Radar Chart\", size=14)\n",
    "ax.grid(True)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c928d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate TNR and FNR at different thresholds\n",
    "def calculate_tnr_fnr(y_true, y_proba, thresholds):\n",
    "    tnr_list = []\n",
    "    fnr_list = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        \n",
    "        tnr = tn / (tn + fp + 1e-10)  # True Negative Rate\n",
    "        fnr = fn / (fn + tp + 1e-10)  # False Negative Rate\n",
    "        \n",
    "        tnr_list.append(tnr)\n",
    "        fnr_list.append(fnr)\n",
    "    \n",
    "    return tnr_list, fnr_list\n",
    "\n",
    "# === Calculate TNR and FNR for different thresholds for each model ===\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "tnr_rf, fnr_rf = calculate_tnr_fnr(y_test, y_proba_rf, thresholds)\n",
    "tnr_xgb, fnr_xgb = calculate_tnr_fnr(y_test, y_proba_xgb, thresholds)\n",
    "tnr_lgbm, fnr_lgbm = calculate_tnr_fnr(y_test, y_proba_lgbm, thresholds)\n",
    "\n",
    "# === Plot TNR and FNR vs Threshold for Each Model ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Random Forest TNR and FNR\n",
    "plt.plot(thresholds, tnr_rf, label='RF TNR', color='blue')\n",
    "plt.plot(thresholds, fnr_rf, label='RF FNR', color='blue', linestyle='--')\n",
    "\n",
    "# XGBoost TNR and FNR\n",
    "plt.plot(thresholds, tnr_xgb, label='XGB TNR', color='green')\n",
    "plt.plot(thresholds, fnr_xgb, label='XGB FNR', color='green', linestyle='--')\n",
    "\n",
    "# LightGBM TNR and FNR\n",
    "plt.plot(thresholds, tnr_lgbm, label='LGBM TNR', color='red')\n",
    "plt.plot(thresholds, fnr_lgbm, label='LGBM FNR', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('TNR and FNR vs. Classification Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
