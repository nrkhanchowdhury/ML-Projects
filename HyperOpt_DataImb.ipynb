{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc722ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# --- Load your dataset ---\n",
    "train_df = pd.read_parquet('train_file.parquet')\n",
    "test_df = pd.read_parquet('test_file.parquet')\n",
    "\n",
    "# Assuming you have your X and y from these datasets\n",
    "X_train = train_df.drop(columns=['target'])  # replace 'target' with your actual target column name\n",
    "y_train = train_df['target']\n",
    "X_test = test_df.drop(columns=['target'])\n",
    "y_test = test_df['target']\n",
    "\n",
    "# --- Function to calculate various metrics ---\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-10)\n",
    "    tnr = tn / (tn + fp + 1e-10)  # True Negative Rate\n",
    "    fnr = fn / (fn + tp + 1e-10)  # False Negative Rate\n",
    "    tpr = recall  # True Positive Rate (same as Recall)\n",
    "    fpr = fp / (fp + tn + 1e-10)  # False Positive Rate\n",
    "    \n",
    "    # ROC AUC and PR AUC\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    \n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'TNR': tnr,\n",
    "        'FNR': fnr,\n",
    "        'TPR': tpr,\n",
    "        'FPR': fpr,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'PR AUC': pr_auc\n",
    "    }\n",
    "\n",
    "# --- Define the hyperparameter search space ---\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
    "    'max_depth': hp.choice('max_depth', [10, 20, None]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4]),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced', None])\n",
    "}\n",
    "\n",
    "# --- Function to evaluate performance for different imbalance ratios ---\n",
    "def evaluate_imbalance_ratios(X_train, y_train, X_test, y_test, imbalance_ratios):\n",
    "    results = []\n",
    "    \n",
    "    for ratio in imbalance_ratios:\n",
    "        # Adjust class weights based on imbalance ratio (for simulation)\n",
    "        class_weights = {0: ratio, 1: 1-ratio}  # 0 is majority class, 1 is minority class\n",
    "        \n",
    "        # Define objective function for Hyperopt\n",
    "        def objective(params):\n",
    "            # Train the model with the given hyperparameters\n",
    "            rf_model = RandomForestClassifier(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                max_depth=params['max_depth'],\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                min_samples_leaf=params['min_samples_leaf'],\n",
    "                max_features=params['max_features'],\n",
    "                class_weight=class_weights,  # Adjusted based on imbalance ratio\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train the model on the full training data\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            y_pred_rf = rf_model.predict(X_test)\n",
    "            y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(y_test, y_pred_rf, y_proba_rf)\n",
    "            \n",
    "            # We want to maximize TNR, so we return the negative TNR for minimization\n",
    "            return {\n",
    "                'loss': -metrics['TNR'],  # Hyperopt minimizes, so we return the negative of TNR\n",
    "                'status': STATUS_OK,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "\n",
    "        # Run Hyperopt to optimize hyperparameters for the current imbalance ratio\n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=objective,          # The objective function to minimize\n",
    "            space=space,           # Search space for the hyperparameters\n",
    "            algo=tpe.suggest,      # Use Tree of Parzen Estimators algorithm for optimization\n",
    "            max_evals=50,          # Number of trials to run\n",
    "            trials=trials          # Store trial results\n",
    "        )\n",
    "        \n",
    "        # Extract metrics for analysis\n",
    "        trial_results = []\n",
    "        for trial in trials.trials:\n",
    "            metrics = trial['result']['metrics']\n",
    "            metrics['Imbalance Ratio'] = ratio  # Store imbalance ratio\n",
    "            trial_results.append(metrics)\n",
    "        \n",
    "        # Append the results of this imbalance ratio to the overall results\n",
    "        results.extend(trial_results)\n",
    "    \n",
    "    # Convert results to DataFrame for easy visualization\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Define class imbalance ratios to evaluate ---\n",
    "imbalance_ratios = [0.9, 0.8, 0.7, 0.6, 0.5]  # Majority class ratio (90%, 80%, etc.)\n",
    "\n",
    "# --- Evaluate model performance across different imbalance ratios ---\n",
    "results_df = evaluate_imbalance_ratios(X_train, y_train, X_test, y_test, imbalance_ratios)\n",
    "\n",
    "# --- Plot model performance for each imbalance ratio ---\n",
    "metrics_to_plot = ['TNR', 'FNR', 'ROC AUC', 'PR AUC']\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    plt.plot(results_df['Imbalance Ratio'], results_df[metric], label=metric)\n",
    "\n",
    "plt.xlabel('Class Imbalance Ratio (Majority Class Proportion)')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Model Performance at Different Class Imbalance Ratios with Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
